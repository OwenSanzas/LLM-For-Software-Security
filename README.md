# LLM-For-Software-Security

A collection of papers and resources related to Large Language Models in：

- Vulnerability Detection
- Vulnerability Repair
- Fuzz Testing & Vulnerability Reproduction
- AI-Powered Automated Data Privacy Detection

The organization of papers refers to our survey "Large Language Models in Software Security: A Survey of
Vulnerability Detection Techniques and Insights".

Please let us know if you find out a mistake or have any suggestions by e-mail: zesheng@tamu.edu

If you find our survey useful for your research, please cite the following paper:

<p align="center">
  <img src="https://github.com/user-attachments/assets/e36cef77-1cab-4c5d-9978-177d61f75380" width="50%">
</p>

## Contributors

<div style="display: flex; gap: 10px;">
  <a href="https://github.com/OwenSanzas">
    <img src="https://avatars.githubusercontent.com/OwenSanzas" width="50px" height="50px" style="border-radius: 50%"/>
  </a>
  <a href="https://github.com/zchengchen">
    <img src="https://avatars.githubusercontent.com/zchengchen" width="50px" height="50px" style="border-radius: 50%"/>
  </a>
  <a href="https://github.com/shuninggu">
    <img src="https://avatars.githubusercontent.com/shuninggu" width="50px" height="50px" style="border-radius: 50%"/>
  </a>
  <a href="https://github.com/SeanLmax">
    <img src="https://avatars.githubusercontent.com/SeanLmax" width="50px" height="50px" style="border-radius: 50%"/>
  </a>
  <a href="https://github.com/MF0-ANT1SHY">
    <img src="https://avatars.githubusercontent.com/MF0-ANT1SHY" width="50px" height="50px" style="border-radius: 50%"/>
  </a>
</div>

Want to join us? Feel free to email zesheng@tamu.edu with your name and organization!

## Latest Update
2025-03-24 20:49:40 [SOSP'24]If At First You Don’t Succeed, Try, Try, Again...? Insights and LLM-informed Tooling for Detecting Retry Bugs in Software Systems

2025-04-01 21:30:54 Add LLM-Fuzz papers [here](https://github.com/SeanLmax/LLM-For-Software-Security/blob/SeanLmax-patch-1/bib/LLM-Fuzzing/README.md#here-are-all-papers-you-want).

## 🚀 Latest News:
AIxCC is a competition that is exploring new LLM-driven system for vulnerability detection. We are happy to announce that our team is one of the finalists!

If you are interested in this area, then these two challenges can be a very nice start for you, make your own AI-powered system to detect bugs in the challenges!

**Linux Kernel Challenge:**
https://github.com/aixcc-public/challenge-001-exemplar

**Nginx Challenge:**
https://github.com/aixcc-public/challenge-004-nginx-cp


## What's in this repository
This repo provides a curated collection of research papers, datasets, tools, and benchmarks related to Large Language Models (LLMs) in vulnerability detection. It aims to help researchers and practitioners stay up to date with the latest advancements in this field.

Specifically, the repository includes:

📄 Survey and Research Papers – A categorized list of papers on LLM-based vulnerability detection, covering different techniques, evaluation methods, and insights.

🛠 Tools and Frameworks – Open-source implementations and toolkits for leveraging LLMs in software security.

🔍 Benchmarks and Datasets – Publicly available datasets and benchmarks for training and evaluating vulnerability detection models.

🚀 Competitions and Challenges – Ongoing and past competitions, including AIxCC challenges, that provide real-world vulnerability detection tasks.

We will continuously update the repository with new papers, tools, and resources to facilitate research and development in this exciting domain. 🚀

